


import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import time
import pytest





class KMeans:
    def __init__(self, n_clusters=3, max_iterations=100, random_state=None):
        if not isinstance(n_clusters, int) or n_clusters <= 0:
            raise ValueError("n_clusters must be a positive integer")
        self.n_clusters = n_clusters
        self.max_iterations = max_iterations
        self.random_state = random_state
        self.centroids = None
        self.labels = None

    def fit(self, data):
        """Fit the KMeans model to the input data.
        
        Args:
            data (numpy.ndarray): Input data of shape (n_samples, n_features) to fit the model to.
            
        Returns:
            self: The fitted KMeans model instance.
            
        Raises:
            ValueError: If input data is empty or has only one sample.
        """
        if len(data.shape) != 2:
            raise ValueError("Input data must be 2-dimensional")
        if data.shape[0] < 2:
            raise ValueError("At least two data points are required for clustering")
        if self.random_state is not None:
            np.random.seed(self.random_state)
        
        m, n = data.shape
        
        random_indices = np.random.choice(m, self.n_clusters, replace=False)
        self.centroids = data[random_indices].astype(np.float64)
        
        for _ in range(self.max_iterations):
            old_centroids = self.centroids.copy()
            
            distances = np.linalg.norm(data[:, np.newaxis] - self.centroids, axis=2)
            self.labels = np.argmin(distances, axis=1)
            
            for k in range(self.n_clusters):
                cluster_points = data[self.labels == k]
                if len(cluster_points) > 0:
                    self.centroids[k] = np.mean(cluster_points, axis=0)
            
            if np.allclose(old_centroids, self.centroids):
                break
                
        return self

    def predict(self, data):
        """Predict cluster labels for input data.
        
        Args:
            data (numpy.ndarray): Input data of shape (n_samples, n_features) to predict clusters for.
            
        Returns:
            numpy.ndarray: Predicted cluster labels for each sample.
            
        Raises:
            ValueError: If predict is called before fitting the model.
        """
        if self.centroids is None:
            raise ValueError("Model must be fit before prediction")
        
        distances = np.linalg.norm(data[:, np.newaxis] - self.centroids, axis=2)
        return np.argmin(distances, axis=1)
    
    def get_centroids(self):
        """
        Get the current centroids after fitting the algorithm.

        Returns:
        - centroids: Numpy array representing the centroids of clusters.
        """
        if self.centroids is None:
            raise ValueError("Centroids not available - model must be fit first")
        return self.centroids







def measure_kmeans_complexity(variable='m', base_m=1000, base_k=3, base_n=2, base_i=100, 
                            range_vals=None):
    """
    Measure KMeans running time while varying one parameter.
    
    Parameters:
    - variable: Parameter to vary ('m', 'k', 'n', or 'i')
    - base_m: Base number of points
    - base_k: Base number of clusters
    - base_n: Base number of dimensions
    - base_i: Base number of iterations
    - range_vals: List of values to test for the chosen variable
    
    Returns:
    - times: List of running times
    - values: List of parameter values tested
    """
    if range_vals is None:
        if variable == 'm':
            range_vals = [1000, 2000, 4000, 8000, 16000]
        elif variable == 'k':
            range_vals = [2, 4, 8, 16, 32]
        elif variable == 'n':
            range_vals = [2, 4, 8, 16, 32]
        elif variable == 'i':
            range_vals = [50, 100, 200, 400, 800]
    
    times = []
    
    for val in range_vals:
        m = val if variable == 'm' else base_m
        k = val if variable == 'k' else base_k
        n = val if variable == 'n' else base_n
        i = val if variable == 'i' else base_i
        
        # Generate random data
        data = np.random.rand(m, n)
        
        # Initialize and time KMeans
        kmeans = KMeans(n_clusters=k, max_iterations=i)
        start_time = time.time()
        kmeans.fit(data)
        end_time = time.time()
        
        times.append(end_time - start_time)
    
    return times, range_vals

variables = ['m', 'k', 'n', 'i']
results = {}

for var in variables:
    times, values = measure_kmeans_complexity(variable=var)
    results[var] = (times, values)

# Create plots
plt.figure(figsize=(15, 10))

for idx, var in enumerate(variables, 1):
    times, values = results[var]
    
    plt.subplot(2, 2, idx)
    plt.plot(values, times, 'o-')
    plt.xlabel(f'Number of {var}')
    plt.ylabel('Time (seconds)')
    plt.title(f'KMeans Runtime vs {var}')
    plt.grid(True)

plt.tight_layout()
plt.show()

# Print analysis
print("\nComplexity Analysis:")
print("-------------------")
print("The K-Means algorithm's time complexity can be broken down as follows:")
print("- m: Number of points - Linear relationship observed")
print("- K: Number of clusters - Linear relationship with some overhead")
print("- n: Number of dimensions - Linear relationship")
print("- I: Number of iterations - Linear relationship")
print("\nTheoretical complexity: O(m * K * n * I)")









# Load and display original image
img = Image.open('parrot.jpg')  # Replace with your image path
img_array = np.array(img)
original_shape = img_array.shape

# Reshape the image to 2D array of pixels (each pixel is a point in R^3 color space)
X = img_array.reshape(-1, 3)

# Apply K-means clustering
n_colors = 16  # Number of colors to reduce to
kmeans = KMeans(n_clusters=n_colors, random_state=42)
kmeans.fit(X)

# Replace each pixel with its corresponding centroid
compressed = kmeans.centroids[kmeans.predict(X)]

# Reshape back to original image dimensions
compressed = compressed.reshape(original_shape)

# Convert back to uint8 type for display
compressed = np.clip(compressed, 0, 255).astype('uint8')

# Display original and compressed images side by side
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(img_array)
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(compressed)
plt.title(f'Compressed Image ({n_colors} colors)')
plt.axis('off')

plt.tight_layout()
plt.show()

# Calculate compression ratio
original_size = img_array.nbytes
compressed_size = n_colors * 3 + len(kmeans.labels)
compression_ratio = original_size / compressed_size

print("\nImage Compression Analysis:")
print("-------------------------")
print(f"Original number of colors: {len(np.unique(img_array.reshape(-1, 3), axis=0))}")
print(f"Compressed to {n_colors} colors")
print(f"Compression ratio: {compression_ratio:.2f}:1")









# Used claude for help with test cases, along with error handling of test cases

def simple_dataset():
    """Create a simple dataset with clear clusters for testing"""
    np.random.seed(42)
    cluster1 = np.random.normal(0, 0.5, (100, 2))
    cluster2 = np.random.normal(4, 0.5, (100, 2))
    cluster3 = np.random.normal([2, 4], 0.5, (100, 2))
    return np.vstack([cluster1, cluster2, cluster3])

def test_kmeans_initialization():
    """Test KMeans initialization with different parameters"""
    kmeans = KMeans(n_clusters=3, max_iterations=100, random_state=42)
    assert kmeans.n_clusters == 3
    assert kmeans.max_iterations == 100
    assert kmeans.random_state == 42
    assert kmeans.centroids is None
    assert kmeans.labels is None

def test_kmeans_fit_predict(simple_dataset):
    """Test basic fitting and prediction functionality"""
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(simple_dataset)
    
    # Check if centroids were computed
    assert kmeans.centroids is not None
    assert kmeans.centroids.shape == (3, 2)
    
    # Check if labels were assigned
    labels = kmeans.predict(simple_dataset)
    assert len(labels) == len(simple_dataset)
    assert len(np.unique(labels)) <= 3

def test_kmeans_convergence():
    """Test if KMeans converges with simple, well-separated data"""
    # Create three distinct points
    data = np.array([[0, 0], [10, 10], [20, 20]])
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(data)
    
    # With distinct points, centroids should exactly match input points
    assert len(kmeans.centroids) == 3
    assert np.allclose(np.sort(kmeans.centroids, axis=0), np.sort(data, axis=0))

def test_kmeans_empty_clusters():
    """Test handling of potential empty clusters"""
    # Create data with only two distinct points but ask for three clusters
    data = np.array([[0, 0], [0, 0], [10, 10], [10, 10]])
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(data)
    
    # Should still complete without errors
    assert kmeans.centroids is not None
    labels = kmeans.predict(data)
    assert len(np.unique(labels)) <= 3

def test_kmeans_random_state():
    """Test reproducibility with random_state"""
    data = np.random.rand(100, 2)
    
    kmeans1 = KMeans(n_clusters=3, random_state=42)
    kmeans2 = KMeans(n_clusters=3, random_state=42)
    
    centroids1 = kmeans1.fit(data).centroids
    centroids2 = kmeans2.fit(data).centroids
    
    assert np.allclose(centroids1, centroids2)

def test_input_validation():
    """Test error handling for invalid inputs"""
    kmeans = KMeans(n_clusters=3)
    
    # Test invalid number of clusters
    with pytest.raises(ValueError):
        KMeans(n_clusters=0)
    
    with pytest.raises(ValueError):
        KMeans(n_clusters=-1)
    
    # Test invalid input data
    with pytest.raises(ValueError):
        kmeans.fit(np.array([]))  # Empty array
    
    with pytest.raises(ValueError):
        kmeans.fit(np.array([[1]]))  # Single sample

def test_predict_without_fit():
    """Test error handling when predict is called before fit"""
    kmeans = KMeans(n_clusters=3)
    data = np.random.rand(10, 2)
    
    with pytest.raises(ValueError):
        kmeans.predict(data)

def test_different_dimensions():
    """Test KMeans with different dimensional data"""
    # Test with 1D data
    data_1d = np.random.rand(100, 1)
    kmeans = KMeans(n_clusters=2, random_state=42)
    kmeans.fit(data_1d)
    assert kmeans.centroids.shape == (2, 1)
    
    # Test with 3D data
    data_3d = np.random.rand(100, 3)
    kmeans = KMeans(n_clusters=2, random_state=42)
    kmeans.fit(data_3d)
    assert kmeans.centroids.shape == (2, 3)

def test_prediction_shape_mismatch():
    """Test error handling for prediction with wrong dimensions"""
    kmeans = KMeans(n_clusters=3, random_state=42)
    train_data = np.random.rand(100, 2)
    kmeans.fit(train_data)
    
    # Try to predict with different dimensions
    test_data = np.random.rand(10, 3)
    with pytest.raises(ValueError):
        kmeans.predict(test_data)


if __name__ == "__main__":
    # Run all test functions
    try:
        test_kmeans_initialization()
        test_kmeans_fit_predict(simple_dataset())
        test_kmeans_convergence()
        test_kmeans_empty_clusters()
        test_kmeans_random_state()
        test_input_validation()
        test_predict_without_fit()
        test_different_dimensions()
        test_prediction_shape_mismatch()
        print("All tests passed successfully!")
    except Exception as e:
        print(f"Tests failed with error: {e}")

